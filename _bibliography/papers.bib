@inproceedings{wu2023gnas,
    abbr={AAAI},
    title={G-NAS: Generalizable Neural Architecture Search for Single Domain Generalization Object Detection},
    abstract={In this paper, we focus on a realistic yet challenging task, Single Domain Generalization Object Detection (S-DGOD), where only one source domain's data can be used for training object detectors, but have to generalize multiple distinct target domains. In S-DGOD, both high-capacity fitting and generalization abilities are needed due to the task's complexity. Differentiable Neural Architecture Search (NAS) is known for its high capacity for complex data fitting and we propose to leverage Differentiable NAS to solve S-DGOD. However, it may confront severe over-fitting issues due to the feature imbalance phenomenon, where parameters optimized by gradient descent are biased to learn from the easy-to-learn features, which are usually non-causal and spuriously correlated to ground truth labels, such as the features of background in object detection data. Consequently, this leads to serious performance degradation, especially in generalizing to unseen target domains with huge domain gaps between the source domain and target domains. To address this issue, we propose the Generalizable loss (G-loss), which is an OoD-aware objective, preventing NAS from over-fitting by using gradient descent to optimize parameters not only on a subset of easy-to-learn features but also the remaining predictive features for generalization, and the overall framework is named G-NAS. Experimental results on the S-DGOD urban-scene datasets demonstrate that the proposed G-NAS achieves SOTA performance compared to baseline methods.},
    author={Wu, Fan and Gao, Jinling and Lanqing, HONG and Wang, Xinbing and Zhou, Chenghu and Ye, Nanyang},
    booktitle={The 38th Annual AAAI Conference on Artificial Intelligence},
    year={2023},
    selected={true},
    bibtex_show={true},
    code={https://github.com/wufan-cse/G-NAS},
    pdf={gnas.pdf},
}

@article{wu2023object,
    abbr={ICLR Workshop},
    title={Object Detection with OOD Generalizable Neural Architecture Search},
    author={Wu, Fan and Li, Kaican and Gao, Jinling and Peng, Chensheng and Lanqing, HONG and Xie, Enze and Li, Zhenguo and Ye, Nanyang},
    journal={ICLR Domain Generalization Workshop},
    year={2023},
    selected={true}
}

@article{wu2022agnet,
    abbr={Journal},
    title={AGNet: Automatic generation network for skin imaging reports},
    author={Wu, Fan and Yang, Haiqiong and Peng, Linlin and Lian, Zongkai and Li, Mingxin and Qu, Gang and Jiang, Shancheng and Han, Yu},
    journal={Computers in Biology and Medicine},
    volume={141},
    pages={105037},
    year={2022},
    publisher={Elsevier},
    selected={true}
}

@article{jiang2021robust,
    abbr={KBS},
    title={A robust end-to-end deep learning framework for detecting Martian landforms with arbitrary orientations},
    author={Jiang, Shancheng and Wu, Fan and Yung, Kai-Leung and Yang, Yingqiao and Ip, WH and Gao, Ming and Foster, James Abbott},
    journal={Knowledge-Based Systems},
    volume={234},
    pages={107562},
    year={2021},
    publisher={Elsevier},
    selected={true}
}
